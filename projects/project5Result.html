<!DOCTYPE HTML>
<html>
	<head>
		<title>e-Portfolio Elias - Projects Page</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="../assets/css/main.css" />
		<noscript><link rel="stylesheet" href="../assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">
			<div id="wrapper">
				<header id="header">
					<div class="inner">
						<div class="button-container">
							<a href="../index.html" class="logo home-button">
								<span class="symbol"><img src="../images/home-icon.png" alt="" /></span><span class="title">Home</span>
							</a>
							<a href="../projects.html" class="logo back-button">
								<span class="symbol"><img src="../images/back-icon.png" alt="" /></span><span class="title">Back</span>
							</a>
						</div>
							<nav>
								<ul>
									<li><a href="#menu">Menu</a></li>
								</ul>
							</nav>
					</div>
				</header>
				<nav id="menu">
					<h2>Menu</h2>
					<ul>
						<button id="darkModeToggle">Toggle Dark Mode</button>
						<br>
						<br>
						<li><a href="../index.html">Home</a></li>
						<li><a href="../modulePages/inductionModule.html">Induction Module</a></li>
						<li><a href="../modulePages/aiFundamentals.html">Understanding Artificial Intelligence</a></li>
						<li><a href="../modulePages/numericalAnalysis.html">Numerical Analysis</a></li>
						<li><a href="../modulePages/machineLearning.html">Machine Learning</a></li>
						<li><a href="../modulePages/knowledgeRep.html">Knowledge Representation and Reasoning</a></li>
						<li><a href="../modulePages/intelligentAgents.html">Intelligent Agents</a></li>
						<li><a href="../modulePages/researchMethods.html">Research Methods and Professional Practice</a></li>
						<li><a href="../modulePages/masterThesis.html">MSc Computing Project</a></li>
						<li><a href="../projects.html">Projects</a></li>
					</ul>
				</nav>
					<div id="main">
						<div class="inner">
							<h1>Project 5: Q-Table Reinforcement Learning Maze Solver</h1>
							<ul class="actions small">
								<li><a href="project5Intro.html" class="button primary">Introduction</a></li>
								<li><a href="project5Part1.html" class="button primary">Part 1</a></li>
								<li><a href="project5Part2.html" class="button primary">Part 2</a></li>
								<li><a href="project5Part3.html" class="button primary">Part 3</a></li>
								<li><a href="project5Result.html" class="button primary disabled">Results</a></li>
							</ul>
							<div class="modern-background">
									<h2>Results</h2>
									<p>The reinforcement learning maze solver highlights its ability to train an agent for efficient maze navigation. Despite the challenges faced, this project helped to understand the nuances of RL model training. I learned that Q-Learning is a very helpful technique to help an agent solve a known problem but it becomes hard to use the same technique to solve "new" problems. For example it can easily learn how to solve complexe mazes as long as it knows the mazes and had a chance to train on them. It does not achieve well in new mazes it has never seen before. I think Q-Learning can be very helpful to detect new patters when solving an issue but not as a general agent that can be used to solve unknonw challenges.</p>
									<div class="video-container">
										<video controls autoplay>
											<source src="../videos/mazeSolver.mp4" type="video/mp4">
											Your browser does not support the video tag.
										</video>
										<br><br>
									</div>
								  
									<p><strong>Key Takeaways</strong></p>
									<ul>
									  <li>Q-Learning can perform well in known environments but is hard to tweak for new environments.</li>
									  <li>Reward and penalty systems effectively guided the agent but required careful adjustment.</li>
									  <li>Dynamic exploration strategies provided a balance between discovering new paths and exploiting known optimal paths.</li>
									  <li>The agent demonstrated some ability to generalize and solve unseen test mazes, though consistency remains a challenge and complex mazes can not be solved.</li>
									</ul>
								  
									<p><strong>Conclusion</strong></p>
									<p>This project demonstrates the potential of reinforcement learning for solving navigation problems, with a focus on achieving generalization over different maze sizes. While small mazes and parkours were navigated successfully, scaling up remains an open challenge. I am currently thinking of heading into the direction of using Deep Q-Networks (DQN) which could be a better fit to train on random mazes to achieve a general maze solver agent.</p>
							</div>
						</div>
					</div>
			</div>

			<script src="../assets/js/jquery.min.js"></script>
			<script src="../assets/js/browser.min.js"></script>
			<script src="../assets/js/breakpoints.min.js"></script>
			<script src="../assets/js/util.js"></script>
			<script src="../assets/js/main.js"></script>
			<script src="../assets/js/darkmode.js"></script>

	</body>
</html>