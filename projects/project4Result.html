<!DOCTYPE HTML>
<html>
	<head>
		<title>e-Portfolio Elias - Projects Page</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="../assets/css/main.css" />
		<noscript><link rel="stylesheet" href="../assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">
			<div id="wrapper">
				<header id="header">
					<div class="inner">
						<div class="button-container">
							<a href="../index.html" class="logo home-button">
								<span class="symbol"><img src="../images/home-icon.png" alt="" /></span><span class="title">Home</span>
							</a>
							<a href="../projects.html" class="logo back-button">
								<span class="symbol"><img src="../images/back-icon.png" alt="" /></span><span class="title">Back</span>
							</a>
						</div>
							<nav>
								<ul>
									<li><a href="#menu">Menu</a></li>
								</ul>
							</nav>
					</div>
				</header>
				<nav id="menu">
					<h2>Menu</h2>
					<ul>
						<button id="darkModeToggle">Toggle Dark Mode</button>
						<br>
						<br>
						<li><a href="../index.html">Home</a></li>
						<li><a href="../modulePages/inductionModule.html">Induction Module</a></li>
						<li><a href="../modulePages/aiFundamentals.html">Understanding Artificial Intelligence</a></li>
						<li><a href="../modulePages/numericalAnalysis.html">Numerical Analysis</a></li>
						<li><a href="../modulePages/machineLearning.html">Machine Learning</a></li>
						<li><a href="../modulePages/knowledgeRep.html">Knowledge Representation and Reasoning</a></li>
						<li><a href="../modulePages/intelligentAgents.html">Intelligent Agents</a></li>
						<li><a href="../modulePages/researchMethods.html">Research Methods and Professional Practice</a></li>
						<li><a href="../modulePages/masterThesis.html">MSc Computing Project</a></li>
						<li><a href="../projects.html">Projects</a></li>
					</ul>
				</nav>
					<div id="main">
						<div class="inner">
							<h1>Project 4: Reinforcement Learning Maze Solver</h1>
							<ul class="actions small">
								<li><a href="project4Intro.html" class="button primary">Introduction</a></li>
								<li><a href="project4Part1.html" class="button primary">Part 1</a></li>
								<li><a href="project4Part2.html" class="button primary">Part 2</a></li>
								<li><a href="project4Part3.html" class="button primary">Part 3</a></li>
								<li><a href="project4Result.html" class="button primary disabled">Results</a></li>
							</ul>
							<div class="modern-background">
									<h2>Results</h2>
									<p>The reinforcement learning maze solver highlights its ability to train an agent for efficient maze navigation. Despite the challenges faced, this project helped to understand the nuances of RL model training. For the result I further downsized the mazes and achieved a high accuracy on a small training and test set.</p>
									<div class="video-container">
										<video controls autoplay>
											<source src="../videos/mazeSolver.mp4" type="video/mp4">
											Your browser does not support the video tag.
										</video>
										<br><br>
									</div>
									<p><strong>Model Performance</strong></p>
									<ul>
									  <li>Developed and trained a Q-learning model capable of navigating mazes with a focus on achieving generalization.</li>
									  <li>Achieved a training success rate of 95.31% for 9 small mazes (6x6), but scaling to larger mazes (even 8x8) introduced challenges most probably due not setting up the reward function correctly.</li>
									  <li>The parameters used where set to alpha = 0.05 (Learning Rate), gamma = 0.99 (Discount Factor) and epsilon = 0.9 (Exploration Rate - decaying dynamically during training).</li>
									</ul>
								  
									<p><strong>Key Takeaways</strong></p>
									<ul>
									  <li>Reward and penalty systems effectively guided the agent but required careful adjustment to avoid overfitting.</li>
									  <li>Dynamic exploration strategies provided a balance between discovering new paths and exploiting known optimal paths.</li>
									  <li>The agent demonstrated some ability to generalize and solve unseen test mazes, though consistency remains a challenge.</li>
									  <li>Scaling to larger mazes (beyond 8x8) revealed limitations in the current approach and parameter set.</li>
									</ul>
								  
									<p><strong>Conclusion and Future Work</strong></p>
									<p>This project demonstrates the potential of reinforcement learning for solving navigation problems, with a focus on achieving generalization over different maze sizes. While small mazes were navigated successfully, scaling up remains an open challenge. Future work will explore enhancements to address these limitations:</p>
									<ul>
									  <li>Further parameter fine-tuning to improve performance on larger, more complex mazes.</li>
									  <li>Doing a deep dive into the rewwards function to increase the RL agent model.</li>
									  <li>Integrating an intuitive GUI for better visualization and user interaction.</li>
									  <li>Introducing alternativ to the Q-tables appraoch like Deep Reinforcement Learning (DRL).</li>
									</ul>
							</div>
						</div>
					</div>
			</div>

			<script src="../assets/js/jquery.min.js"></script>
			<script src="../assets/js/browser.min.js"></script>
			<script src="../assets/js/breakpoints.min.js"></script>
			<script src="../assets/js/util.js"></script>
			<script src="../assets/js/main.js"></script>
			<script src="../assets/js/darkmode.js"></script>

	</body>
</html>